{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load market_sales.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "from bokeh.io import output_file,show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    stock = sys.argv[1]\n",
    "else:\n",
    "    stock = 'goog'\n",
    "    \n",
    "plot=True\n",
    "debug=True\n",
    "mynanstring=\"NAAN\"\n",
    "num_pat=re.compile(\"-?[0-9]{1,9}[\\.,]?[0-9]{0,2}\")\n",
    "\n",
    "\"\"\" URLS \"\"\" \n",
    "url_sales_ninc_eps=\"http://www.marketwatch.com/investing/stock/\"+stock+\"/financials/\"\n",
    "url_roic=\"http://www.marketwatch.com/investing/stock/\"+stock+\"/profile\"\n",
    "url_fcf=\"http://www.marketwatch.com/investing/stock/\"+stock+\"/financials/cash-flow/\"\n",
    "url_bvps=\"https://www.gurufocus.com/term/Book+Value+Per+Share/\"+stock+\"/Book-Value-per-Share\"\n",
    "\n",
    "\"\"\"         Functions           \"\"\"  \n",
    "def err_web(url):\n",
    "    \"\"\" Catch the Errors from the Web Connections             \"\"\"\n",
    "    \"\"\" All or nothing here: If not 200 OK - exit the program \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url,timeout=10)\n",
    "        #raise_for_status() never execs is connect/timeout occurs\n",
    "        r.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"HTTP Error:\",errh)\n",
    "        sys.exit(1)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"Fatal Error Connecting:\",errc)\n",
    "        sys.exit(1)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"Timeout Error:\",errt)\n",
    "        sys.exit(1)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"OOps: Something Else\",err)\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return r\n",
    "            \n",
    "def get_web_data():\n",
    "    \"\"\" Get Data \"\"\"\n",
    "    print (\"Retrieving HTML for \",stock)\n",
    "    r_sales_ninc_eps = err_web(url_sales_ninc_eps)\n",
    "    r_roic = err_web(url_roic)\n",
    "    r_url_fcf = requests.get(url_fcf)\n",
    "    r_bvps = requests.get(url_bvps)\n",
    "    return r_sales_ninc_eps,r_roic,r_url_fcf,r_bvps \n",
    "\n",
    "def make_soup(r_sales_ninc_eps,r_url_fcf,r_bvps,r_roic):\n",
    "    \"\"\"         Soup Setup        \"\"\"\n",
    "    print (\"Parsing HTML\")\n",
    "    #if you make it here, soup objects will be assigned ok\n",
    "    soup_sales_ninc_eps  = bsoup(r_sales_ninc_eps.content,\"lxml\")\n",
    "    soup_fcf  = bsoup(r_url_fcf.content,\"lxml\")\n",
    "    soup_bvps = bsoup(r_bvps.content,\"lxml\")\n",
    "    soup_roic = bsoup(r_roic.content,\"lxml\")\n",
    "    print (\"Pulling Data out of HTML\")\n",
    "    print (\"\")\n",
    "    return soup_sales_ninc_eps,soup_fcf,soup_bvps,soup_roic\n",
    "\n",
    "def nreny():\n",
    "    \"\"\" Save some typing on a deeply nested if \"\"\"\n",
    "    print(\"No rev/eps/netinc years\")\n",
    "\n",
    "def calc_growth(last,first,period):\n",
    "    \"\"\" Simple cagr calculation \"\"\"\n",
    "    return ((last/first)**(1/period)-1)\n",
    "\n",
    "def prettify_num(num):\n",
    "    \"\"\" Pretty print Growth Rate \"\"\"\n",
    "    return '%.2f'%(num*100)+\"%\"\n",
    " \n",
    "def check_data(data):\n",
    "    \"\"\" Return a Number and a Denomination Value (typically M or B)    \"\"\"\n",
    "    \"\"\" Ensure each list is filled by returning NAJO if no match       \"\"\"\n",
    "    \n",
    "    if data is None:\n",
    "        return None,None\n",
    "    else:\n",
    "        data_pat=re.compile(\"([-(]?[-(]?[0-9,]+\\.?[0-9]{,2})([mMbB]?)\")\n",
    "        data_is_valid=data_pat.search(data)\n",
    "        if data_is_valid:\n",
    "            num   = data_is_valid.group(1)\n",
    "            denom = data_is_valid.group(2)\n",
    "            brc_pat=re.compile(\"\\(\")           \n",
    "            braces=brc_pat.search(num)\n",
    "            num = num.replace('(',\"\")\n",
    "            num = num.replace(')',\"\")\n",
    "            num = num.replace(\",\",\"\")\n",
    "                    \n",
    "            if denom:\n",
    "                denom_val=denom\n",
    "            else:\n",
    "                denom_val=None\n",
    "            \n",
    "            if braces:\n",
    "                neg_pat=re.compile(\"-\")\n",
    "                is_neg_already=neg_pat.search(num)\n",
    "                if is_neg_already:\n",
    "                    return  float(num),denom_val\n",
    "                else:\n",
    "                    return -float(num),denom_val\n",
    "            else:\n",
    "                #print (\"else\",float(num))\n",
    "                return float(num),denom_val\n",
    "        else:\n",
    "            return mynanstring,mynanstring\n",
    "\n",
    "\n",
    "def get_years_rev_ninc_eps(soup_sales_ninc_eps):\n",
    "    \"\"\" Years (Revenue,Net Inc and EPS - including USD and EUR \"\"\"\n",
    "    \n",
    "    years_rev_ninc_eps=[]\n",
    "    rev_text_pattern = re.compile(\"Fiscal year is \\w+-\\w+. All values \\w+ millions\")\n",
    "    years_main_th_tag = soup_sales_ninc_eps.find('th',text=rev_text_pattern)\n",
    "    try:\n",
    "       years_links=years_main_th_tag.find_next_siblings()\n",
    "    except AttributeError as e:\n",
    "        print(\"No Rev-EPS-NINC web data patterns found\")\n",
    "        print(\"\") \n",
    "        years_rev_ninc_eps=False\n",
    "        return years_rev_ninc_eps\n",
    "    else:\n",
    "        rev_years_pattern = re.compile(\"201[0-9]\")\n",
    "        if years_links is not None:\n",
    "            max=5\n",
    "            for tag in years_links:\n",
    "                if len(years_rev_ninc_eps) == max:\n",
    "                    return years_rev_ninc_eps\n",
    "                else:\n",
    "                    years_link_data=tag.string\n",
    "                    if years_link_data is not None:\n",
    "                        if rev_years_pattern.match(years_link_data):\n",
    "                            years_rev_ninc_eps.append(years_link_data)\n",
    "                        else:\n",
    "                            years_rev_ninc_eps.append(mynanstring)\n",
    "        return years_rev_ninc_eps\n",
    "                                     \n",
    "def get_rev(soup_sales_ninc_eps,years_rev_ninc_eps):    \n",
    "    \"\"\"                      Revenue                       \"\"\"\n",
    "    revenue_master=[]\n",
    "    revenue_inc_denom=''\n",
    "    revenue_denom_master=[]\n",
    "        \n",
    "    a_href_sales = soup_sales_ninc_eps.find('a',attrs={'data-ref':'ratio_SalesNet1YrGrowth'})\n",
    "    \"\"\" If we got here the http call succeeded so we will have a valid soup object  \n",
    "        However, if no content found in a soup obj, bsoup returns a NoneType.\n",
    "        So worst case a_href_sales becomes NoneType, but we don't kick up an AttributeError here.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \"\"\" if the soup object is null we will kick up the AttributeError here, so we try and group together.\"\"\"\n",
    "        sales_td_parent = a_href_sales.find_parent()\n",
    "        sales_data_links = sales_td_parent.find_next_siblings(\"td\",attrs={'class':'valueCell'})\n",
    "    except AttributeError as e:\n",
    "        print(\"No Sales data web patterns found\")\n",
    "        print(\"\")    \n",
    "        revenue=False\n",
    "        return revenue,revenue_master,revenue_inc_denom\n",
    "    else:\n",
    "        if sales_data_links is not None:\n",
    "            for link in sales_data_links:\n",
    "                     rev_val=link.string\n",
    "                     safe,denom_val = check_data(rev_val)\n",
    "                     revenue_master.append(safe)\n",
    "                     revenue_denom_master.append(denom_val)\n",
    "        \n",
    "        #Kludgily find the denominations we are looking for\n",
    "        if all( x==revenue_denom_master[0] for x in revenue_denom_master):\n",
    "            revenue_inc_denom=revenue_denom_master[0]+\"illions\"\n",
    "        elif ( 'B' or 'b' ) in revenue_denom_master and ( 'M' or 'm' )  in revenue_denom_master:\n",
    "            for i,(x,y) in enumerate(zip(revenue_denom_master,revenue_master)):\n",
    "                if 'b' in x or 'B' in x:\n",
    "                    revenue_master[i]=revenue_master[i]*1000\n",
    "            revenue_inc_denom=\"Millions\"\n",
    "        else:\n",
    "            revenue_inc_denom=\"Dollars\"\n",
    "           \n",
    "        \"\"\" Extra checks to avoid script blow up         \"\"\"\n",
    "        \"\"\" And create our dataframe to calculating CAGR \"\"\"\n",
    "        if all(isinstance(item, float) for item in revenue_master)  and mynanstring not in years_rev_ninc_eps and \\\n",
    "        len(revenue_master) == len (years_rev_ninc_eps):\n",
    "            revincdf = pd.DataFrame( { 'years' : years_rev_ninc_eps, 'years_strings': [ int(x) for x in years_rev_ninc_eps ], 'data' : revenue_master } )\n",
    "            revenue_growth_master = ((revincdf['data'].max()/revincdf['data']) ** (1/(revincdf['years_strings'].max()-revincdf['years_strings']))-1)\n",
    "            revenue_growth_master = revenue_growth_master.apply(prettify_num)\n",
    "            revenue=True\n",
    "        else:\n",
    "            revenue=False\n",
    "            revenue_growth_master=['NA', 'NA', 'NA', 'NA', 'NA']\n",
    "            \n",
    "        zipped_years=zip(years_rev_ninc_eps,revenue_master,revenue_growth_master)\n",
    "        for year,rev,gr in zipped_years:\n",
    "            print (stock,\"had\",rev,\"Revenue in\",year,\" Rate = \",gr)\n",
    "        print(\"\")\n",
    "        return revenue,revenue_master,revenue_inc_denom\n",
    "    \n",
    "        \n",
    "def get_ninc(soup_sales_ninc_eps,years_rev_ninc_eps):\n",
    "    \"\"\"                    Net Income                      \"\"\"\n",
    "    net_inc_denom=''\n",
    "    net_inc_master=[]\n",
    "    net_inc_denom_master=[]\n",
    "    \n",
    "    main_net_income_link = soup_sales_ninc_eps.find('td',attrs={'class':'rowTitle'},\\\n",
    "    text=\"Net Income Available to Common\")\n",
    "    try:\n",
    "        net_income_values = main_net_income_link.fetchNextSiblings('td',class_=\"valueCell\")\n",
    "    except AttributeError as e:\n",
    "        print(\"No Net Income data web patterns found\")\n",
    "        print(\"\") \n",
    "        net_inc=False\n",
    "        return net_inc,net_inc_master,net_inc_denom\n",
    "    else:        \n",
    "        for link in net_income_values:\n",
    "            net_income_val=link.string\n",
    "            safe,denom_val = check_data(net_income_val)\n",
    "            net_inc_master.append(safe)\n",
    "            net_inc_denom_master.append(denom_val)\n",
    "                                   \n",
    "        if all( x==net_inc_denom_master[0] for x in net_inc_denom_master):\n",
    "            net_inc_denom=net_inc_denom_master[0]+\"illions\"\n",
    "        elif ( 'B' or 'b' ) in net_inc_denom_master and ( 'M' or 'm') in net_inc_denom_master:\n",
    "            for i,(x,y) in enumerate(zip(net_inc_denom_master,net_inc_master)):\n",
    "                if 'b' in x or 'B' in x:\n",
    "                    net_inc_master[i]=net_inc_master[i]*1000\n",
    "            net_inc_denom=\"Millions\"\n",
    "        else:\n",
    "            net_inc_denom=\"Dollars\"\n",
    "      \n",
    "        if all(isinstance(item, float) for item in net_inc_master) and mynanstring not in years_rev_ninc_eps\\\n",
    "        and len(net_inc_master) == len (years_rev_ninc_eps):\n",
    "            netincdf = pd.DataFrame( { 'years' : years_rev_ninc_eps, 'years_strings': [ int(x) for x in years_rev_ninc_eps ], 'data' : net_inc_master } )\n",
    "            net_inc_growth_master = ((netincdf['data'].max()/netincdf['data']) ** (1/(netincdf['years_strings'].max()-netincdf['years_strings']))-1)\n",
    "            net_inc_growth_master = net_inc_growth_master.apply(prettify_num)\n",
    "        else:\n",
    "             net_inc_growth_master= ['NA', 'NA', 'NA', 'NA', 'NA']\n",
    "        \n",
    "        \"\"\" Net Income Summary \"\"\" \n",
    "        zipped_ninc=zip(years_rev_ninc_eps,net_inc_master,net_inc_growth_master)\n",
    "        for year,ninc,gr in zipped_ninc:\n",
    "            print (stock,\"had\",ninc,\"Net Income in\",year,\" Rate = \"+gr)\n",
    "        print(\"\")\n",
    "        net_inc=True\n",
    "        return net_inc,net_inc_master,net_inc_denom\n",
    "\n",
    "def get_eps(soup_sales_ninc_eps,years_rev_ninc_eps):\n",
    "    \"\"\"              EPS                       \"\"\"\n",
    "    eps_master=[]\n",
    "    eps_denom_master=[]\n",
    "    eps_growth_master=[]\n",
    "    \n",
    "    main_eps_a_tag = soup_sales_ninc_eps.find('a',attrs={'data-ref':'ratio_Eps1YrAnnualGrowth'})\n",
    "    try:\n",
    "        main_eps_td_tag_parent = main_eps_a_tag.find_parent()\n",
    "        eps_data=main_eps_td_tag_parent.find_next_siblings('td',attrs={'class':'valueCell'})\n",
    "    except AttributeError as e:\n",
    "        print(\"No EPS data web patterns found\")\n",
    "        print(\"\") \n",
    "        eps=False\n",
    "        return eps,eps_master\n",
    "    else:\n",
    "        if eps_data is None:\n",
    "            print(\"No EPS data found at all\")\n",
    "            print(\"\")    \n",
    "            eps=False\n",
    "            return eps,eps_master\n",
    "        else:\n",
    "            for tag in eps_data:\n",
    "                        eps_val=tag.string\n",
    "                        safe,denom_val = check_data(eps_val)\n",
    "                        eps_master.append(safe)\n",
    "                        eps_denom_master.append(denom_val)\n",
    "                    \n",
    "            if all(isinstance(item, float) for item in eps_master) and mynanstring not in years_rev_ninc_eps and \\\n",
    "            len(eps_master) == len (years_rev_ninc_eps):\n",
    "                epsdf = pd.DataFrame( { 'years' : years_rev_ninc_eps, 'years_strings': [ int(x) for x in years_rev_ninc_eps ], 'data' : eps_master } )\n",
    "                eps_growth_master = ((epsdf['data'].max()/epsdf['data']) ** (1/(epsdf['years_strings'].max()-epsdf['years_strings']))-1)\n",
    "                eps_growth_master = eps_growth_master.apply(prettify_num)\n",
    "            else:\n",
    "                eps_growth_master= ['NA', 'NA', 'NA', 'NA', 'NA']\n",
    "          \n",
    "            \"\"\"Summary\"\"\"\n",
    "            zipped_eps=zip(years_rev_ninc_eps,eps_master,eps_growth_master)\n",
    "            for year,es,gr in zipped_eps:\n",
    "                print (stock,\"had\",es,\"EPS in\",year,\" Rate = \",gr)\n",
    "            print(\"\")\n",
    "            eps=True\n",
    "            return eps,eps_master\n",
    "     \n",
    "    \n",
    "def get_fcf(soup_fcf):\n",
    "    \"\"\"                                      Free Cash Flow                 \"\"\"\n",
    "    fcf_denom=''\n",
    "    years_fcf=[]\n",
    "    fcf_master=[]\n",
    "    fcf_denom_master=[]\n",
    "    \n",
    "    pattern = re.compile(\"\\s+Free Cash Flow\")\n",
    "    fcf_text = soup_fcf.find(text=pattern)\n",
    "    try:\n",
    "        fcf_link_parent = fcf_text.find_parent()\n",
    "        fcf_data = fcf_link_parent.find_next_siblings(attrs={'class':'valueCell'})\n",
    "    except AttributeError as e:\n",
    "        print(\"No FCF data web patterns found\")\n",
    "        print(\"\")\n",
    "        fcf=False\n",
    "        return fcf,fcf_master,fcf_denom,years_fcf\n",
    "    else:        \n",
    "        for tag in fcf_data:\n",
    "                fcf_val=tag.string\n",
    "                safe,denom_val = check_data(fcf_val)\n",
    "                fcf_master.append(safe)\n",
    "                fcf_denom_master.append(denom_val)     \n",
    "        \n",
    "        if all( x==fcf_denom_master[0] for x in fcf_denom_master):\n",
    "            fcf_denom=fcf_denom_master[0]+\"illions\"\n",
    "        elif ( 'B' or 'b' ) in fcf_denom_master and ( 'M' or 'm' )  in fcf_denom_master:\n",
    "            for i,(x,y) in enumerate(zip(fcf_denom_master,fcf_master)):\n",
    "                if 'b' in x or 'B' in x:\n",
    "                    fcf_master[i]=fcf_master[i]*1000\n",
    "                    fcf_denom=\"Millions\"\n",
    "        else:\n",
    "            fcf_denom=\"Dollars\"\n",
    "        \n",
    "        \"\"\"Fcf Years\"\"\"  \n",
    "        fcf_years_text_h2 = soup_fcf.find('h2',text=\"Financing Activities\")\n",
    "        try:\n",
    "            fcf_years_data_th=fcf_years_text_h2.find_next('th',attrs={'class':'rowTitle'})\n",
    "            fcf_years_data = fcf_years_data_th.find_next_siblings()\n",
    "            fcf_years_pattern = re.compile(\"201[0-9]\")\n",
    "        except AttributeError as e:\n",
    "            print(\"No FCF years web patterns found\")\n",
    "            print(\"\")\n",
    "            fcf=False\n",
    "            return fcf,fcf_master,fcf_denom,years_fcf\n",
    "        else:\n",
    "            for fcf_year in fcf_years_data:\n",
    "                if fcf_year.string is not None and fcf_years_pattern.match(fcf_year.string):\n",
    "                        years_fcf.append(fcf_year.string)\n",
    "          \n",
    "            if all(isinstance(item, float) for item in fcf_master) and mynanstring not in years_fcf and \\\n",
    "            len(fcf_master) == len (years_fcf) and all( item > 0 for item in fcf_master):\n",
    "                fcfdf = pd.DataFrame( { 'years' : years_fcf, 'years_strings': [ int(x) for x in years_fcf ], 'data' : fcf_master } )\n",
    "                fcf_growth_master = ((fcfdf['data'].max()/fcfdf['data']) ** (1/(fcfdf['years_strings'].max()-fcfdf['years_strings']))-1)\n",
    "                fcf_growth_master = fcf_growth_master.apply(prettify_num)        \n",
    "            else:\n",
    "                fcf_growth_master= ['NA', 'NA', 'NA', 'NA', 'NA']\n",
    "                 \n",
    "            \"\"\"Summary\"\"\"       \n",
    "            zipped_fcf=zip(years_fcf,fcf_master,fcf_growth_master)\n",
    "            for year,fcfl,gr in zipped_fcf:\n",
    "                print (stock,\"had\",fcfl,\"Free Cash Flow in\",year,\" Rate = \"+gr)\n",
    "            print(\"\")\n",
    "            fcf=True\n",
    "            return fcf,fcf_master,fcf_denom,years_fcf\n",
    "\n",
    "def get_bvps(soup_bvps):\n",
    "    \"\"\"                                        BVPS                \"\"\"\n",
    "    years_bvps=[]\n",
    "    bvps_master=[]\n",
    "    bvps_denom_master=[]\n",
    "    \n",
    "    main_bvps_td_tag=soup_bvps.find('td',text=\"Book Value per Share\")\n",
    "    main_bvps_years = soup_bvps.find('div',attrs={'id':'target_def_historical_data'})\n",
    "    try:\n",
    "        bvps_data_in_links = main_bvps_td_tag.find_next_siblings()\n",
    "        bvps_years_data = main_bvps_years.find_next('td').find_next_siblings()\n",
    "    except AttributeError as e:\n",
    "        print(\"No BVPS data web patterns found\")\n",
    "        print(\"\")\n",
    "        bvps=False\n",
    "        return bvps,bvps_master,years_bvps\n",
    "    else:   \n",
    "        if bvps_data_in_links is not None:\n",
    "            for tag in bvps_data_in_links:\n",
    "                #print (\"tag:\",tag)    \n",
    "                #print (\"tag.string:\",tag.string)\n",
    "                bvps_val=tag.string\n",
    "                safe,denom_val = check_data(bvps_val)\n",
    "                if safe is not None:\n",
    "                    bvps_master.append(safe)\n",
    "                    bvps_denom_master.append(denom_val)\n",
    "        else:\n",
    "            bvps=False\n",
    "            print(\"No BVPS data found\")\n",
    "            return bvps,bvps_master,years_bvps                \n",
    "        \n",
    "        \"\"\"Years\"\"\"\n",
    "        bvps_years_pat=re.compile('[0-9]{2}')\n",
    "        if bvps_years_data is not None and len(bvps_years_data) > 0:\n",
    "            for year in bvps_years_data[-5:]:\n",
    "                #year will break w/html \\'s, use year.string\n",
    "                #just get the last 5 values\n",
    "                matched_bvps_year = bvps_years_pat.search(year.string)\n",
    "                if matched_bvps_year:\n",
    "                    bvps_year = \"20\"+matched_bvps_year.group()\n",
    "                    years_bvps.append(bvps_year)\n",
    "                else:\n",
    "                    bvps=False\n",
    "                    print(\"No BVPS years data pattern found\")\n",
    "                    print('')\n",
    "                    return bvps,bvps_master,years_bvps                \n",
    "        else:\n",
    "            bvps=False\n",
    "            print(\"No BVPS years data found\")\n",
    "            print('')\n",
    "            return bvps,bvps_master,years_bvps                \n",
    "    \n",
    "        if all(isinstance(item, float) for item in bvps_master) and mynanstring not in years_bvps and \\\n",
    "        len(bvps_master) == len(years_bvps) and len(bvps_master) > 0 and all( item > 0 for item in bvps_master):\n",
    "            bvdf = pd.DataFrame( { 'years' : years_bvps , 'years_strings': [ int(x) for x in years_bvps ], 'data' : bvps_master } )\n",
    "            bvps_growth_master = ((bvdf['data'].max()/bvdf['data']) ** (1/(bvdf['years_strings'].max()-bvdf['years_strings']))-1)\n",
    "            bvps_growth_master = bvps_growth_master.apply(prettify_num)\n",
    "            bvps=True\n",
    "        else:\n",
    "            bvps_growth_master= ['NA', 'NA', 'NA', 'NA', 'NA']                              \n",
    "            \n",
    "        \"\"\"Summary\"\"\"\n",
    "        bvps=True\n",
    "        zipped_bvps=zip(years_bvps,bvps_master,bvps_growth_master)\n",
    "        for year,bv,gr in zipped_bvps:\n",
    "            print (stock,\"had\",bv,\"BVPS in\",year,\" Rate = \",gr)\n",
    "        print(\"\")\n",
    "        return bvps,bvps_master,years_bvps\n",
    "    \n",
    "def get_roic(soup_roic):\n",
    "    \"\"\"               ROIC                     \"\"\"\n",
    "    pattern= re.compile(\"Return on Invested Capital\")\n",
    "    roic_p_tag=soup_roic.find('p',attrs={'class':'column'},text=pattern)\n",
    "    try:\n",
    "        roic_data=roic_p_tag.find_next_sibling('p',attrs={'class':'data lastcolumn'})\n",
    "        #We are not actually plotting RIC as it's just one value. Leave as NavString\n",
    "    except AttributeError as e:\n",
    "        print(\"No Roic data web patterns found\")\n",
    "        print(\"\")    \n",
    "        roic=False\n",
    "        return roic\n",
    "    else:\n",
    "        roic=roic_data.string\n",
    "        print (stock,\"had\",roic,\"ROIC\")\n",
    "        print(\"\")\n",
    "        return roic\n",
    "\n",
    "\"\"\" Data Checks \"\"\"\n",
    "def check_years(years_bvps,years_rev_ninc_eps,years_fcf):\n",
    "    if years_bvps ==  years_rev_ninc_eps == years_fcf == years_rev_ninc_eps:\n",
    "        print (\"OK: years_bvps,years_rev_ninc_eps,years_fcf, years_rev_ninc_eps are equal\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Check years - something may be off\" )\n",
    "        \n",
    "        \n",
    "def check_data_blocks(eps_master,revenue_master,fcf_master,bvps_master,net_inc_master):\n",
    "    if len(eps_master) == 5 and len(revenue_master) == 5 and len(fcf_master) == 5 and len(bvps_master) == 5 and len(net_inc_master) == 5:\n",
    "        print (\"OK: EPS, Revenue, FCF, BVPS, and Net Income all have 5 years of data\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Check data - some data missing\")\n",
    "\n",
    "def get_links():\n",
    "    \"\"\"         Links                                     \"\"\"\n",
    "    links={ url_sales_ninc_eps:\"Sales,NetInc,EPS\", url_roic : \"Roic\", url_fcf : \"Fcf\", url_bvps:\"Bvps\" }\n",
    "    for link,text in links.items():\n",
    "        print(link+\" =\",text)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def data_is_filled(years_bvps,years_rev_ninc_eps,years_fcf,eps_master,revenue_master,fcf_master,bvps_master,net_inc_master):\n",
    "    if check_years(years_bvps,years_rev_ninc_eps,years_fcf) and check_data_blocks(eps_master,revenue_master,fcf_master,bvps_master,net_inc_master):\n",
    "            print (\"GREAT: Data for \"+stock+\" is filled for all years and big 5 numbers\")\n",
    "\n",
    "def plot_or_not(stock,roic,revenue,years_rev_ninc_eps,revenue_master,revenue_inc_denom,net_inc,net_inc_master,net_inc_denom,eps,eps_master,bvps,years_bvps,bvps_master,fcf,years_fcf,fcf_master,fcf_denom):\n",
    "    \"\"\" Bokeh is ***awesome**** \"\"\"\n",
    "    ###print (roic,revenue,net_inc,bvps,eps,fcf)\n",
    "    if plot:\n",
    "        if (not roic) and (not revenue) and (not net_inc) and (not bvps) and (not eps) and (not fcf):\n",
    "            print (\"No data - plot will not be generated\")\n",
    "            print(\"\")\n",
    "        else:\n",
    "            stock=stock.upper()\n",
    "            print (\"Plotting details for\",stock)\n",
    "            print (\"\")\n",
    "            output_file(\"data/\"+stock+\".html\", title=stock+\" Financials\")\n",
    "            plot_net_inc = figure(plot_width=400, plot_height=400,title=stock+\" Net Income\", x_axis_label='Years',\\\n",
    "            y_axis_label='Net Income')\n",
    "            plot_net_inc.line(years_rev_ninc_eps,net_inc_master,legend=net_inc_denom, line_width=2)\n",
    "            \n",
    "            \n",
    "            plot_rev = figure(plot_width=400, plot_height=400,title=stock+\" Revenue\", x_axis_label='Years',\\\n",
    "            y_axis_label='Revenue')\n",
    "            plot_rev.line(years_rev_ninc_eps,revenue_master,legend=revenue_inc_denom, line_width=2)\n",
    "            \n",
    "            \n",
    "            plot_eps = figure(plot_width=400, plot_height=400,title=stock+\" EPS\", x_axis_label='Years',\\\n",
    "            y_axis_label='EPS')\n",
    "            plot_eps.line(years_rev_ninc_eps,eps_master,legend=\"Dollars per Share\", line_width=2)\n",
    "            \n",
    "            \n",
    "            plot_bvps = figure(plot_width=400, plot_height=400,title=stock+\" BVPS\", x_axis_label='Years',\\\n",
    "            y_axis_label='BVPS')\n",
    "            plot_bvps.line(years_bvps,bvps_master,legend=\"Book Value per Share\", line_width=2)\n",
    "            \n",
    "            \n",
    "            plot_fcf = figure(plot_width=400, plot_height=400,title=stock+\" Free Cash Flow\", x_axis_label='Years',\\\n",
    "            y_axis_label='Free Cash Flow')\n",
    "            plot_fcf.line(years_fcf,fcf_master,legend=fcf_denom, line_width=2)\n",
    "            \n",
    "            plot_roic = figure(plot_width=400, plot_height=400,title=stock+\" Roic\")\n",
    "            plot_roic.line([1,2,3,4,5],[1,2,3,4,5],legend=roic)\n",
    "            \n",
    "            # put all the plots in a grid layout\n",
    "            p = gridplot( [[plot_rev,plot_net_inc,plot_eps],[plot_bvps,plot_fcf,plot_roic]] )\n",
    "            show(p)\n",
    "\n",
    "def main():\n",
    "      \n",
    "    r_sales_ninc_eps,r_roic,r_url_fcf,r_bvps                    = get_web_data()\n",
    "    soup_sales_ninc_eps,soup_fcf,soup_bvps,soup_roic            = make_soup(r_sales_ninc_eps,r_url_fcf,r_bvps,r_roic)\n",
    "    years_rev_ninc_eps                                          = get_years_rev_ninc_eps(soup_sales_ninc_eps)\n",
    "    revenue,revenue_master,revenue_inc_denom                    = get_rev(soup_sales_ninc_eps,years_rev_ninc_eps)\n",
    "    net_inc,net_inc_master,net_inc_denom                        = get_ninc(soup_sales_ninc_eps,years_rev_ninc_eps)\n",
    "    eps,eps_master                                              = get_eps(soup_sales_ninc_eps,years_rev_ninc_eps)\n",
    "    fcf,fcf_master,fcf_denom,years_fcf                          = get_fcf(soup_fcf)\n",
    "    bvps,bvps_master,years_bvps                                 = get_bvps(soup_bvps)\n",
    "    roic                                                        = get_roic(soup_roic)\n",
    "    get_links()\n",
    "    plot_or_not(stock,roic,revenue,years_rev_ninc_eps,revenue_master,revenue_inc_denom,net_inc,net_inc_master,net_inc_denom,eps,eps_master,bvps,years_bvps,bvps_master,fcf,years_fcf,fcf_master,fcf_denom)\n",
    "    if debug:\n",
    "        data_is_filled(years_bvps,years_rev_ninc_eps,years_fcf,eps_master,revenue_master,fcf_master,bvps_master,net_inc_master)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving HTML for  goog\n",
      "Parsing HTML\n",
      "Pulling Data out of HTML\n",
      "\n",
      "goog had 49.96 Revenue in 2012  Rate =  15.77%\n",
      "goog had 59.73 Revenue in 2013  Rate =  14.53%\n",
      "goog had 65.83 Revenue in 2014  Rate =  16.75%\n",
      "goog had 73.59 Revenue in 2015  Rate =  21.93%\n",
      "goog had 89.73 Revenue in 2016  Rate =  0.00%\n",
      "\n",
      "goog had 10.74 Net Income in 2012  Rate = 16.05%\n",
      "goog had 12.16 Net Income in 2013  Rate = 17.01%\n",
      "goog had 13.4 Net Income in 2014  Rate = 20.57%\n",
      "goog had 15.83 Net Income in 2015  Rate = 23.06%\n",
      "goog had 19.48 Net Income in 2016  Rate = 0.00%\n",
      "\n",
      "goog had 16.42 EPS in 2012  Rate =  14.60%\n",
      "goog had 18.29 EPS in 2013  Rate =  15.69%\n",
      "goog had 19.82 EPS in 2014  Rate =  19.53%\n",
      "goog had 23.12 EPS in 2015  Rate =  22.49%\n",
      "goog had 28.32 EPS in 2016  Rate =  0.00%\n",
      "\n",
      "goog had 13.35 Free Cash Flow in 2012  Rate = 17.93%\n",
      "goog had 11.3 Free Cash Flow in 2013  Rate = 31.71%\n",
      "goog had 11.42 Free Cash Flow in 2014  Rate = 50.36%\n",
      "goog had 16.11 Free Cash Flow in 2015  Rate = 60.27%\n",
      "goog had 25.82 Free Cash Flow in 2016  Rate = 0.00%\n",
      "\n",
      "goog had 108.77 BVPS in 2012  Rate =  16.61%\n",
      "goog had 130.12 BVPS in 2013  Rate =  15.62%\n",
      "goog had 152.49 BVPS in 2014  Rate =  14.85%\n",
      "goog had 175.07 BVPS in 2015  Rate =  14.89%\n",
      "goog had 201.13 BVPS in 2016  Rate =  0.00%\n",
      "\n",
      "goog had 14.68 ROIC\n",
      "\n",
      "http://www.marketwatch.com/investing/stock/goog/financials/ = Sales,NetInc,EPS\n",
      "http://www.marketwatch.com/investing/stock/goog/profile = Roic\n",
      "http://www.marketwatch.com/investing/stock/goog/financials/cash-flow/ = Fcf\n",
      "https://www.gurufocus.com/term/Book+Value+Per+Share/goog/Book-Value-per-Share = Bvps\n",
      "\n",
      "Plotting details for GOOG\n",
      "\n",
      "OK: years_bvps,years_rev_ninc_eps,years_fcf, years_rev_ninc_eps are equal\n",
      "OK: EPS, Revenue, FCF, BVPS, and Net Income all have 5 years of data\n",
      "GREAT: Data for goog is filled for all years and big 5 numbers\n"
     ]
    }
   ],
   "source": [
    "%run ./market_sales.py goog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
